full_book_title = "Nouveau (le) testament",
author_code = "au0000615;",
author_name = NA,
stated_publication_places = NA,
stated_publication_years = "1709")
toJSON(foo)
?write
write(bar, file = "foo.json")
bar = toJSON(foo)
write(bar, file = "foo.json")
foo$match[[1]]$`__value__`[[1]] = list(ID = 1089.0,
UUID = "ca134a74-e9fd-40ea-90b3-25bcde95c345",
super_book_code = NULL,
full_book_title = "Nouveau (le) testament",
author_code = "au0000615;",
author_name = NULL,
stated_publication_places = NULL,
stated_publication_years = "1709")
bar = toJSON(foo)
write(bar, file = "foo.json")
foo = list()
foo$distinct = list()
foo$match = list()
foo$match[[1]] = list()
foo$match[[1]]$`__class__` = "tuple"
foo$match[[1]]$`__value__` = list()
foo$match[[1]]$`__value__`[[1]] = list(ID = 1089.0,
UUID = "ca134a74-e9fd-40ea-90b3-25bcde95c345",
super_book_code = NULL,
full_book_title = "Nouveau (le) testament",
author_code = "au0000615;",
author_name = NULL,
stated_publication_places = NULL,
stated_publication_years = "1709")
foo$match[[1]]$`__value__`[[2]] = list(ID = 1089.0,
UUID = "ca134a74-e9fd-40ea-90b3-25bcde95c345",
super_book_code = NULL,
full_book_title = "Nouveau (le) testament",
author_code = "au0000615;",
author_name = NULL,
stated_publication_places = NULL,
stated_publication_years = "1709")
foo$match[[2]]$`__value__`[[1]] = list(ID = 1089.0,
UUID = "ca134a74-e9fd-40ea-90b3-25bcde95c345",
super_book_code = NULL,
full_book_title = "Nouveau (le) testament",
author_code = "au0000615;",
author_name = NULL,
stated_publication_places = NULL,
stated_publication_years = "1709")
foo$match[[2]]$`__value__`[[2]] = list(ID = 1089.0,
UUID = "ca134a74-e9fd-40ea-90b3-25bcde95c345",
super_book_code = NULL,
full_book_title = "Nouveau (le) testament",
author_code = "au0000615;",
author_name = NULL,
stated_publication_places = NULL,
stated_publication_years = "1709")
bar = toJSON(foo)
write(bar, file = "foo.json")
library(tidyverse)
library(rjson)
library(magrittr)
rm(list = ls())
library(tidyverse)
library(rjson)
library(magrittr)
# Import the data
data <- read_csv("combined_editions_illegal_books.csv")
data
foo = list()
foo$distinct = list()
foo$match = list()
seq(1, 1000)
rm(foo)
data
data %>% group_by(super_book_code) %>% summarise(n = n()) %>% filter(n > 1)
sample(data)
sample_n(data, 1)
list(sample_n(data, 1))
?purrr::transpose
transpose(sample_n(data, 1))
as.vector(sample_n(data, 1))
transpose(sample_n(data, 1))
transpose(sample_n(data, 1)) %>% as.character()
transpose(sample_n(data, 1)) %>% unlist()
sample_n(data, 1) %>% unlist()
foo <- sample_n(data, 1) %>% unlist()
foo["super_book_code"]
for (i in seq(1:2)) {
# Select first book from among those with super_book_codes
book1 <- data %>%
filter(!is.na(super_book_code)) %>% # books with codes
sample_n(1) %>% # get one
unlist() # convert to named vector
# Select second, non-matching book
book2 <- data %>%
filter(!is.na(super_book_code) & # books with codes
super_book_code != book1["super_book_code"]) %>% # that don't match book 1
sample_n(1) %>% # get one
unlist() # convert to named vector
# Now add to the list
training_data$distinct[[i]] <- list() # create new entry
training_data$distinct[[i]]$`__class__` <- "tuple" # specify class (always 'tuple')
training_data$distinct[[i]]$`__value__` <- list()
training_data$distinct[[i]]$`__value__`[[1]] <- book1
training_data$distinct[[i]]$`__value__`[[2]] <- book2
}
# Initialise the list
training_data = list()
training_data$distinct = list()
training_data$match = list()
# Start with "distinct". We want 1000 random pairs of books that are not the same.
for (i in seq(1:2)) {
# Select first book from among those with super_book_codes
book1 <- data %>%
filter(!is.na(super_book_code)) %>% # books with codes
sample_n(1) %>% # get one
unlist() # convert to named vector
# Select second, non-matching book
book2 <- data %>%
filter(!is.na(super_book_code) & # books with codes
super_book_code != book1["super_book_code"]) %>% # that don't match book 1
sample_n(1) %>% # get one
unlist() # convert to named vector
# Now add to the list
training_data$distinct[[i]] <- list() # create new entry
training_data$distinct[[i]]$`__class__` <- "tuple" # specify class (always 'tuple')
training_data$distinct[[i]]$`__value__` <- list()
training_data$distinct[[i]]$`__value__`[[1]] <- book1
training_data$distinct[[i]]$`__value__`[[2]] <- book2
}
bar = toJSON(training_data)
write(bar, file = "foo.json")
book1
book1[is.na(book1)] <- NULL
book1[is.na(book1)] <- c(NULL)
class(bar)
book1[1] <- null
book1[1] <- NULL
c(foo = NULL)
c(foo = NULL, bar = 1)
as.list(book1)
is.na(book1)
book1 <- as.list(book1)
book
book1
is.na(book1)
book1[is.na(book1)] <- NULL
book1
book1 <- data %>%
filter(!is.na(super_book_code)) %>% # books with codes
sample_n(1) %>% # get one
unlist() %>% # convert to named vector
as.list()
book1
book1$ID = NULL
book1
?rjson
for (i in seq(1:2)) {
# Select first book from among those with super_book_codes
book1 <- data %>%
filter(!is.na(super_book_code)) %>% # books with codes
sample_n(1) %>% # get one
unlist() %>% # convert to named vector
as.list() # then to list
# Select second, non-matching book
book2 <- data %>%
filter(!is.na(super_book_code) & # books with codes
super_book_code != book1["super_book_code"]) %>% # that don't match book 1
sample_n(1) %>% # get one
unlist() # convert to named vector
# Now add to the list
training_data$distinct[[i]] <- list() # create new entry
training_data$distinct[[i]]$`__class__` <- "tuple" # specify class (always 'tuple')
training_data$distinct[[i]]$`__value__` <- list()
training_data$distinct[[i]]$`__value__`[[1]] <- book1
training_data$distinct[[i]]$`__value__`[[2]] <- book2
}
bar = toJSON(training_data)
bar
str_replace(bar, "\"NA\"", "null")
str_replace(bar, "\\\"NA\\\"", "null")
str_replace(bar, "\\"NA\\"", "null")
str_replace(bar, "[\]\"NA[\]\"", "null")
str_replace(bar, "[\\]\"NA[\\]\"", "null")
str_replace(bar, "\\["]NA\\["]", "null")
str_replace(bar, "[\]["]NA[\]["]", "null")
str_replace(bar, "[\\]["]NA[\\]["]", "null")
str_replace(bar, "\\["]NA\\["]", "null")
str_replace(bar, ":\\["]NA\\["]", "null")
str_replace(bar, ":\\["]NA\\\\"", "null")
str_replace(bar, ":\\\"NA\\\"", "null")
str_replace_all(bar, "\\\"NA\\\"", "null")
coded_illegals <- data %>%
filter(!is.na(UUID) & !is.na(super_book_code))
for (i in 1:nrow(coded_illegals)) {
# Select first book from among those with super_book_codes
book1 <- coded_illegals[i,] %>%
unlist() %>% # convert to named vector
as.list() # then to list
# Select second, non-matching book from among the rest
book2 <- data %>%
filter(super_book_code == book1["super_book_code"]) %>% # find books that match book 1
sample_n(1) %>% # choose one
unlist() # convert to named vector
# Now add to the list
training_data$match[[i]] <- list() # create new entry
training_data$match[[i]]$`__class__` <- "tuple" # specify class (always 'tuple')
training_data$match[[i]]$`__value__` <- list()
training_data$match[[i]]$`__value__`[[1]] <- book1
training_data$match[[i]]$`__value__`[[2]] <- book2
}
nrow(coded_illegals)
training_json = toJSON(training_data) %>%
str_replace_all(bar, "\\\"NA\\\"", "null") # change NAs into nulls
write(bar, file = "marked_pairs.json")
coded_illegals[1,]
library(tidyverse)
library(rjson)
library(magrittr)
# Import the data
data <- read_csv("combined_editions_illegal_books.csv")
# Initialise the list
training_data = list()
training_data$distinct = list()
training_data$match = list()
# Start with "distinct". We want 1000 random pairs of books that are not the same.
for (i in seq(1:1000)) {
# Select first book from among those with super_book_codes
book1 <- data %>%
filter(!is.na(super_book_code)) %>% # books with codes
sample_n(1) %>% # get one
unlist() %>% # convert to named vector
# Select second, non-matching book
book2 <- data %>%
filter(!is.na(super_book_code) & # books with codes
super_book_code != book1["super_book_code"]) %>% # that don't match book 1
sample_n(1) %>% # get one
unlist() # convert to named vector
# Now add to the list
training_data$distinct[[i]] <- list() # create new entry
training_data$distinct[[i]]$`__class__` <- "tuple" # specify class (always 'tuple')
training_data$distinct[[i]]$`__value__` <- list()
training_data$distinct[[i]]$`__value__`[[1]] <- book1
training_data$distinct[[i]]$`__value__`[[2]] <- book2
}
# Now add to "matches." First we want to include all the illegal books that already have super_book_codes
coded_illegals <- data %>%
filter(!is.na(UUID) & !is.na(super_book_code))
for (i in 1:nrow(coded_illegals)) {
# Select first book from among those with super_book_codes
book1 <- coded_illegals[i,] %>%
unlist() %>% # convert to named vector
# Select second, non-matching book from among the rest
book2 <- data %>%
filter(super_book_code == book1["super_book_code"]) %>% # find books that match book 1
sample_n(1) %>% # choose one
unlist() # convert to named vector
# Now add to the list
training_data$match[[i]] <- list() # create new entry
training_data$match[[i]]$`__class__` <- "tuple" # specify class (always 'tuple')
training_data$match[[i]]$`__value__` <- list()
training_data$match[[i]]$`__value__`[[1]] <- book1
training_data$match[[i]]$`__value__`[[2]] <- book2
}
# Start with "distinct". We want 1000 random pairs of books that are not the same.
for (i in seq(1:1000)) {
# Select first book from among those with super_book_codes
book1 <- data %>%
filter(!is.na(super_book_code)) %>% # books with codes
sample_n(1) %>% # get one
unlist() # convert to named vector
# Select second, non-matching book
book2 <- data %>%
filter(!is.na(super_book_code) & # books with codes
super_book_code != book1["super_book_code"]) %>% # that don't match book 1
sample_n(1) %>% # get one
unlist() # convert to named vector
# Now add to the list
training_data$distinct[[i]] <- list() # create new entry
training_data$distinct[[i]]$`__class__` <- "tuple" # specify class (always 'tuple')
training_data$distinct[[i]]$`__value__` <- list()
training_data$distinct[[i]]$`__value__`[[1]] <- book1
training_data$distinct[[i]]$`__value__`[[2]] <- book2
}
# Now add to "matches." First we want to include all the illegal books that already have super_book_codes
coded_illegals <- data %>%
filter(!is.na(UUID) & !is.na(super_book_code))
for (i in 1:nrow(coded_illegals)) {
# Select first book from among those with super_book_codes
book1 <- coded_illegals[i,] %>%
unlist() # convert to named vector
# Select second, non-matching book from among the rest
book2 <- data %>%
filter(super_book_code == book1["super_book_code"]) %>% # find books that match book 1
sample_n(1) %>% # choose one
unlist() # convert to named vector
# Now add to the list
training_data$match[[i]] <- list() # create new entry
training_data$match[[i]]$`__class__` <- "tuple" # specify class (always 'tuple')
training_data$match[[i]]$`__value__` <- list()
training_data$match[[i]]$`__value__`[[1]] <- book1
training_data$match[[i]]$`__value__`[[2]] <- book2
}
training_json = toJSON(training_data) %>%
str_replace_all(bar, "\\\"NA\\\"", "null") # change NAs into nulls
length(training_data)
length(training_data$distinct)
training_data$distinct[[1]]
training_json = toJSON(training_data)
training_json
training_json = toJSON(training_data) %>%
str_replace_all("\\\"NA\\\"", "null")
write(training_json, file = "marked_pairs.json")
# Add another 500 matches for good measure
start <- length(training_data$match + 1)
# Add another 500 matches for good measure
start <- length(training_data$match) + 1
start
for (i in start:(start + 500)) {
# Select first book from among those with super_book_codes
book1 <- coded_illegals[i,] %>%
unlist() # convert to named vector
# Select second, non-matching book from among the rest
book2 <- data %>%
filter(super_book_code == book1["super_book_code"]) %>% # find books that match book 1
sample_n(1) %>% # choose one
unlist() # convert to named vector
# Now add to the list
training_data$match[[i]] <- list() # create new entry
training_data$match[[i]]$`__class__` <- "tuple" # specify class (always 'tuple')
training_data$match[[i]]$`__value__` <- list()
training_data$match[[i]]$`__value__`[[1]] <- book1
training_data$match[[i]]$`__value__`[[2]] <- book2
}
########################################################################################################
#
# MPCE Record Linkage Project
#
# Project: Mapping Print, Charting Enlightenment
#
# Script: Generating training data for Dedupe
#
# Author: Michael Falk
#
# Date: 19/11/18
#
########################################################################################################
# In an effort to improve the accuracy of our intelligent deduper, this script generates a few thousand
# training pairs for the model to work with.
library(tidyverse)
library(rjson)
library(magrittr)
# Import the data
data <- read_csv("combined_editions_illegal_books.csv")
# Initialise the list
training_data = list()
training_data$distinct = list()
training_data$match = list()
# Start with "distinct". We want 1000 random pairs of books that are not the same.
for (i in seq(1:1000)) {
# Select first book from among those with super_book_codes
book1 <- data %>%
filter(!is.na(super_book_code)) %>% # books with codes
sample_n(1) %>% # get one
unlist() # convert to named vector
# Select second, non-matching book
book2 <- data %>%
filter(!is.na(super_book_code) & # books with codes
super_book_code != book1["super_book_code"]) %>% # that don't match book 1
sample_n(1) %>% # get one
unlist() # convert to named vector
# Now add to the list
training_data$distinct[[i]] <- list() # create new entry
training_data$distinct[[i]]$`__class__` <- "tuple" # specify class (always 'tuple')
training_data$distinct[[i]]$`__value__` <- list()
training_data$distinct[[i]]$`__value__`[[1]] <- book1
training_data$distinct[[i]]$`__value__`[[2]] <- book2
}
# Now add to "matches." First we want to include all the illegal books that already have super_book_codes
coded_illegals <- data %>%
filter(!is.na(UUID) & !is.na(super_book_code))
for (i in 1:nrow(coded_illegals)) {
# Select first book from among those with super_book_codes
book1 <- coded_illegals[i,] %>%
unlist() # convert to named vector
# Select second, matching book from among the rest
book2 <- data %>%
filter(super_book_code == book1["super_book_code"]) %>% # find books that match book 1
sample_n(1) %>% # choose one
unlist() # convert to named vector
# Now add to the list
training_data$match[[i]] <- list() # create new entry
training_data$match[[i]]$`__class__` <- "tuple" # specify class (always 'tuple')
training_data$match[[i]]$`__value__` <- list()
training_data$match[[i]]$`__value__`[[1]] <- book1
training_data$match[[i]]$`__value__`[[2]] <- book2
}
# Add another 500 matches for good measure
start <- length(training_data$match) + 1 # start after the end of the illegal books matches (don't want to overwrite!)
for (i in start:(start + 500)) {
# Select first book from among those with super_book_codes
book1 <- data %>%
filter(is.na(UUID) & # ignore illegal books, we've been through those already
!is.na(super_book_code)) %>% # books with codes
sample_n(1) %>% # get one
unlist() # convert to named vector
# Select second, matching book
book2 <- data %>%
filter(is.na(UUID) & # ignore illegal books
!is.na(super_book_code) & # books with codes
super_book_code == book1["super_book_code"]) %>% # that match book 1
sample_n(1) %>% # get one
unlist() # convert to named vector
# Now add to the list
training_data$match[[i]] <- list() # create new entry
training_data$match[[i]]$`__class__` <- "tuple" # specify class (always 'tuple')
training_data$match[[i]]$`__value__` <- list()
training_data$match[[i]]$`__value__`[[1]] <- book1
training_data$match[[i]]$`__value__`[[2]] <- book2
}
training_json = toJSON(training_data) %>%
str_replace_all("\\\"NA\\\"", "null") # change NAs into nulls
write(training_json, file = "marked_pairs.json")
length(training_data$match)
training_data$match[97]
training_data$match[98]
########################################################################################################
#
# MPCE Record Linkage Project
#
# Project: Mapping Print, Charting Enlightenment
#
# Script: Generating training data for Dedupe
#
# Author: Michael Falk
#
# Date: 19/11/18
#
########################################################################################################
# In an effort to improve the accuracy of our intelligent deduper, this script generates a few thousand
# training pairs for the model to work with.
library(tidyverse)
library(rjson)
library(magrittr)
# Import the data
data <- read_csv("combined_editions_illegal_books.csv")
# Initialise the list
training_data = list()
training_data$distinct = list()
training_data$match = list()
# Start with "distinct". We want 1000 random pairs of books that are not the same.
for (i in seq(1:1000)) {
# Select first book from among those with super_book_codes
book1 <- data %>%
filter(!is.na(super_book_code)) %>% # books with codes
sample_n(1) %>% # get one
unlist() # convert to named vector
# Select second, non-matching book
book2 <- data %>%
filter(!is.na(super_book_code) & # books with codes
super_book_code != book1["super_book_code"]) %>% # that don't match book 1
sample_n(1) %>% # get one
unlist() # convert to named vector
# Now add to the list
training_data$distinct[[i]] <- list() # create new entry
training_data$distinct[[i]][[1]] <- book1
training_data$distinct[[i]][[2]] <- book2
}
# Now add to "matches." First we want to include all the illegal books that already have super_book_codes
coded_illegals <- data %>%
filter(!is.na(UUID) & !is.na(super_book_code))
for (i in 1:nrow(coded_illegals)) {
# Select first book from among those with super_book_codes
book1 <- coded_illegals[i,] %>%
unlist() # convert to named vector
# Select second, matching book from among the rest
book2 <- data %>%
filter(super_book_code == book1["super_book_code"]) %>% # find books that match book 1
sample_n(1) %>% # choose one
unlist() # convert to named vector
# Now add to the list
training_data$match[[i]] <- list() # create new entry
training_data$match[[i]][[1]] <- book1
training_data$match[[i]][[2]] <- book2
}
# Add another 500 matches for good measure
start <- length(training_data$match) + 1 # start after the end of the illegal books matches (don't want to overwrite!)
for (i in start:(start + 500)) {
# Select first book from among those with super_book_codes
book1 <- data %>%
filter(is.na(UUID) & # ignore illegal books, we've been through those already
!is.na(super_book_code)) %>% # books with codes
sample_n(1) %>% # get one
unlist() # convert to named vector
# Select second, matching book
book2 <- data %>%
filter(is.na(UUID) & # ignore illegal books
!is.na(super_book_code) & # books with codes
super_book_code == book1["super_book_code"]) %>% # that match book 1
sample_n(1) %>% # get one
unlist() # convert to named vector
# Now add to the list
training_data$match[[i]] <- list() # create new entry
training_data$match[[i]][[1]] <- book1
training_data$match[[i]][[2]] <- book2
}
training_json = toJSON(training_data) %>%
str_replace_all("\\\"NA\\\"", "null") # change NAs into nulls
write(training_json, file = "marked_pairs.json")
rm(list = ls())
