{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning `super_book_codes` to the banned books\n",
    "\n",
    "**Author:** Michael Falk\n",
    "\n",
    "**Date:** 31/10/18-1/11/18, 6/11/18, 12/11/18\n",
    "\n",
    "## Background\n",
    "\n",
    "One of the key datasets for *Mapping Print, Charting Enlightenment* is a set of documents concerning illegal books in eighteenth-century France. BNF MS 21928-9 contains a list of banned books. It is unclear who exactly wrote the list, but it appears to have been prepared by the central government to assist book inspectors with their tasks across France. BNF Arsenal MS 10305 is an inventory of all the books that were found in the Bastille when it was stormed during the French Revolution. The actual MS has disappeared, but luckily a modern edition exists.\n",
    "\n",
    "A problem occured during entry of the data. The interface was supposed to oblige the user to assign a 'super book code' to each title in the banned books lists upon entry. But due to a glitch in the interface, the lookup took too long at it was impossible to efficiently do so. Accordingly, only 97 of the 1000+ illegal books have a 'super book code' assigned to them. The data is therefore not linked to the rest of the database and is useless for analysis.\n",
    "\n",
    "To speed up the process of linking all the data, this notebook uses 'dedupe', an open-source record linkage library, to try and find links between these banned titles and the titles already recorded elsewhere in the database. Hopefully this will speed up record linkage, and provide a testbed for other record linkage tasks in the project.\n",
    "\n",
    "**Update:** Better versions of the helper functions defined in this notebook have been saved in the file *dedupe_helper_functions.py* in this repo.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Import data, initialise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.1: Load necessary libraries and define key paths\n",
    "import dedupe as dd\n",
    "import pandas as pd\n",
    "import os as os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from dedupe_helper_functions import dedupe_initialise, run_deduper, save_clusters\n",
    "import json\n",
    "\n",
    "input_file = \"combined_editions_illegal_books.csv\"\n",
    "output_file = \"illegal_books_deduped.csv\"\n",
    "settings_file = \"illegal_books_learned_settings\"\n",
    "training_file = \"illegal_books_training.json\"\n",
    "output_file = \"illegal_books_clustered.csv\"\n",
    "marked_pairs_file = \"marked_pairs.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was preprocessed in R. The full set of 'editions' was extracted from the database. The illegal_titles data was cleaned, and the two datasets were combined into a single large table. The script is in this repo. This preprocessing means that the problem is now a problem of finding duplicate rows in a single table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 17164 rows, 1921 of which need super_book_codes assigned.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1.2: Import data\n",
    "data_frame = pd.read_csv(input_file)\n",
    "\n",
    "print(f\"The data has {data_frame.shape[0]} rows, {data_frame[data_frame['super_book_code'].isna()].shape[0]} of which need super_book_codes assigned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.3: Initialise deduper\n",
    "\n",
    "# Creat a list of fields for the model to look at. NB: 'ID' and 'UUID' are not relevant to the task,\n",
    "# hence do not appear in the list. The 'super_book_code' also encodes no useful information,\n",
    "# because the problem is that we have records without codes, and the model will learn to focus on that\n",
    "# column too much if we include it, since it is a nearly perfect determinant of identity.\n",
    "fields = [\n",
    "    {'field':'full_book_title', 'type': 'String'},\n",
    "    {'field':'author_name', 'type': 'String'},\n",
    "    {'field':'stated_publication_places', 'type': 'String'},\n",
    "    {'field':'stated_publication_years', 'type': 'DateTime'}\n",
    "]\n",
    "\n",
    "# This line creates the Dedupe model. If it finds a file at the 'settings_file', it will load as a 'static'\n",
    "# deduper that can be used efficiently to cluster data, but that cannot be trained. If there is no\n",
    "# settings file at the given path, it will initialise as an active deduper that must be trained before it can be used.\n",
    "deduper = dedupe_initialise(data_frame, fields, settings_file, training_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Training the Model\n",
    "\n",
    "In this section of the notebook, we give training data to the model so it can learn to identify which books are the same.\n",
    "\n",
    "On 12/12/18, MF tried an alternative training regimen, where the model only looked at the title of the book. It did not do well! Only 9 clusters were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.1: Adding training data to the model (console)\n",
    "\n",
    "# Run this cell to open the console labeller, which allows you to manually enter training data in the output window.\n",
    "dd.consoleLabel(deduper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.2: Adding training data to the model (marked pairs json file)\n",
    "\n",
    "# Run this cell to import the training json file generated by 'illegal_books_get_marked_pairs.R', and add it to the model.\n",
    "with open(marked_pairs_file, 'r') as f:\n",
    "    marked_pairs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dedupe.training:Ran out of predicates: Dedupe tries to find blocking rules that will work well with your data. Sometimes it can't find great ones, and you'll get this warning. It means that there are some pairs of true records that dedupe may never compare. If you are getting bad results, try increasing the `max_comparison` argument to the train method\n",
      "INFO:dedupe.training:Final predicate set:\n",
      "INFO:dedupe.training:SimplePredicate: (metaphoneToken, full_book_title)\n",
      "INFO:dedupe.training:SimplePredicate: (commonFourGram, full_book_title)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2.3: Add the marked pairs to model\n",
    "deduper.markPairs(marked_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Inspecting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.1. Add cluster data back to original data frame and save to csv\n",
    "_ = save_clusters(matches, data_frame, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.2. Sanity check. How good are the model's assignments?\n",
    "# Run this cell a few times to look at different random clusters\n",
    "data_frame[data_frame['cluster'] == random.randint(0, len(matches) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532 illegal books have been given super_book_codes, of 1921 that lack them.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3.3. How much time have we saved? How many illegal books have been assigned a super_book_code?\n",
    "assigned = data_frame[\n",
    "    pd.notnull(data_frame['cluster']) & # which books have been assigned a cluster?\n",
    "    pd.notnull(data_frame['UUID']) & # only illegal books have UUIDs\n",
    "    pd.isna(data_frame['super_book_code']) # only interested in books that didn't already have super_book_codes\n",
    "].shape[0]\n",
    "\n",
    "total = data_frame[\n",
    "    pd.notnull(data_frame['UUID']) &\n",
    "    pd.isna(data_frame['super_book_code'])\n",
    "].shape[0]\n",
    "\n",
    "print(f\"{assigned} illegal books have been given super_book_codes, of {total} that lack them.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can consider the accuracy of the model more accurately by seeing how often it clustered books with different super_book_codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 3386.0 clusters found by dedupe, 717 contain multiple superbooks.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3.4. Inspecting the super_book_codes in all the clusters.\n",
    "multi_groups = (data_frame.groupby(by=\"cluster\")['super_book_code'] # group into clusters, inspect 'super_book_code'\n",
    "               .nunique() # count how many unqiue 'super_book_codes' are in the cluster\n",
    "               .where(lambda x: x > 1) # only keep clusters with more than one 'super_book_code'\n",
    "               .dropna()) # drop the NaNs created by .where()\n",
    "\n",
    "print(f\"Of the {data_frame.cluster.max()} clusters found by dedupe, {len(multi_groups)} contain multiple superbooks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.5. Which books has Dedupe confounded?\n",
    "# Pick one of the groups\n",
    "rand_multi = int(random.choice(multi_groups.index.tolist()))\n",
    "\n",
    "# Inspect it\n",
    "data_frame[data_frame['cluster'] == rand_multi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any clusters where it has put more than one illegal book?\n",
    "multi_illegal = (data_frame[pd.notnull(data_frame['UUID'])]\n",
    "                 .groupby(by = 'cluster')['UUID']\n",
    "                 .nunique()\n",
    "                 .where(lambda x: x > 1)\n",
    "                 .dropna())\n",
    "\n",
    "print(f\"Of the {len(matches)} clusters found by dedupe, {len(multi_illegal)} contain multiple illegal books.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine some of these ones:\n",
    "# Pick one of the groups\n",
    "rand_multi = int(random.choice(multi_illegal.index.tolist()))\n",
    "\n",
    "# Inspect it\n",
    "data_frame[data_frame['cluster'] == rand_multi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Using the results\n",
    "\n",
    "The question is: how to use the results? The most obvious course seems to be to be this: go through all the illegal books, and keep the most confident result that the model has put out. Then we can manually go over them, and if they are okay, update the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you are revisiting this notebook after training, and need to load\n",
    "# the clusters from a previous run.\n",
    "data_frame = pd.read_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_illegals = []\n",
    "top_cluster = int(data_frame['cluster'].max())\n",
    "\n",
    "for i in range(top_cluster): # loop over all clusters\n",
    "    this_slice = data_frame[data_frame.cluster == i] # inspect this cluster\n",
    "    if any(pd.notnull(this_slice.UUID) & # if there is a banned book ...\n",
    "        pd.isnull(this_slice.super_book_code) # ... without a super_book_code...\n",
    "    ) & any(pd.isnull(this_slice.UUID)): # ... and there a super_book_code in the cluster, then:\n",
    "        idx = this_slice[pd.notnull(this_slice.super_book_code)].confidence.idxmax() # find the highest confidence row with an sbc\n",
    "        sbc = this_slice.loc[idx].super_book_code # get the super book code\n",
    "        \n",
    "        banned_books = this_slice[pd.notnull(this_slice.UUID)] # get the banned books in the slice\n",
    "        \n",
    "        for book in banned_books.itertuples(): # loop over banned books\n",
    "            new_match = {}\n",
    "            new_match['UUID'] = book.UUID\n",
    "            new_match['super_book_code'] = sbc\n",
    "            new_match['confidence'] = book.confidence\n",
    "            matched_illegals.append(new_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7842538356781006'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(matched_illegals[22]['confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell writes the results into an SQL file that can be used to update the illegal books table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write this out as an SQL command\n",
    "sql_statement = \"USE manuscripts;\\nALTER TABLE manuscript_titles_illegal ADD confidence FLOAT;\\n\"\n",
    "\n",
    "for match in matched_illegals:\n",
    "    sql_statement += 'UPDATE manuscript_titles_illegal\\n'\n",
    "    sql_statement += 'SET illegal_super_book_code = \"' + match['super_book_code'] + '\",\\n'\n",
    "    sql_statement += 'confidence = \"' + str(match['confidence']) + '\"\\n'\n",
    "    sql_statement += 'WHERE UUID = \"' + match['UUID'] + '\";\\n'\n",
    "    \n",
    "with open('update_illegal_books.sql', 'w', encoding='utf-8') as sql_file:\n",
    "    sql_file.write(sql_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Dedupe appears to do a good job in linking the illegal books to super books that are already in the dataset. The question is whether the ~1600 books the algorithm could not cluster are new books that aren't already in our dataset, or if the algorithm has low recall.\n",
    "\n",
    "Manual investigation will be necessary to see if the ~1600 super books are already in the database.\n",
    "\n",
    "It may also be possible to tune the model further, by\n",
    "1. giving it more training data, or\n",
    "2. increasing the `recall_weight` so that the model cares more about finding possible matches than being accurate when it does find them.\n",
    "\n",
    "**Addendum (12/11/2018):** Simon reckons that finding `super_book_codes` for ~300 of the illegal books is unsurprising. His hunch is that the authorities were quite good at extinguishing banned titles most of the time in *ancien r&eacute;gime* France.\n",
    "\n",
    "**Addendum (19/11/2018):** I tried generating a whole lot of training data, using the super book codes to find matching and non-matching pairs. Feeding this to the model using the `Dedupe.markPairs()` method, the model's recall jumped considerably, and it has found 600+ matches with the illegal books. Now to check that data and upload it...\n",
    "\n",
    "**Addendum (12/12/2018):** Chat with SB on 11/12. We investigated how many books are likely to already be in the dataset. Only 183 of the Bastille Register books were in FBTEE-1, so finding 400 clusters seems a reasonable amount."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
