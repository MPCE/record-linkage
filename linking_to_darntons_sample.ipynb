{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linking Darnton's *Literary Tour de France* to FBTEE\n",
    "\n",
    "**Authors:** Michael Falk, Simon Burrows\n",
    "\n",
    "**Date:** 5/11/2018-\n",
    "\n",
    "## Background\n",
    "\n",
    "The Soci&eacute;t&eacute; Typographique de Neuch&acirc;tel (STN) has been the subject of two major academic studies: Robert Darnton's *A Literary Tour De France*, and *The French Book Trade in Enlightenment Europe*, by Simon Burrows, Mark Curran et al. Each study took a different approach. Darnton closely considered the correspondence that the STN had with a small selection of its most regular buyers. Burrows, Curran et al created a database drawn mostly from the STN's ledgers. The two projects thus wound up focussing on opposite sides of the STN's activities. Darnton was more interested in demand for different titles, Burrows, Curran et al in what the STN actually supplied.\n",
    "\n",
    "In this branch of the *Mapping Print, Charting Enlightenment* project, we try to join these two datasets together. Using machine learning, we will locate linked records, and for the first time will be able to systematically study the relation between supply and demand for this important enlightenment publishing house.\n",
    "\n",
    "**A note on the data:** This repository has an MIT licence, while Darnton's sample is released under a Creative Commons 4. To avoid possible clashes, Darnton's data has not been replicated here. It can be found on his project website: http://robertdarnton.org/sites/default/files/CommandesLibrairesfrancais.xls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Transaction Data\n",
    "\n",
    "In this first experiment, we try to link the orders in Darnton's dataset directly to the sales in the FBTEE data. If this doesn't work, we may try the simpler option of simply trying to get the `book_code` or `super_book_code` for each title in Darnton's spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and define main paths\n",
    "import dedupe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from dedupe_helper_functions import dedupe_initialise, run_deduper, save_clusters\n",
    "import random\n",
    "\n",
    "# Define main paths\n",
    "dar_dir = \"darnton_files/\"\n",
    "input_file = dar_dir + \"darnton_combined.csv\"\n",
    "output_file = dar_dir + \"darnton_deduped.csv\"\n",
    "settings_file = dar_dir + \"darnton_learned_settings\"\n",
    "training_file = dar_dir + \"darnton_training.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having imported the main libraries and defined the main paths, we can import the data and initialise the deduplication model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from csv\n",
    "with open(input_file, 'r', encoding='utf-8') as csv:\n",
    "    darnton_df = pd.read_csv(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the data:\n",
    "darnton_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.api:((SimplePredicate: (alphaNumericPredicate, client_code), TfidfTextCanopyPredicate: (0.4, full_book_title)),)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pre-trained model from darnton_files/darnton_learned_settings...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Define the fields to examine and initialise the model:\n",
    "fields = [\n",
    "    {'field':'stn_abbreviated_title', 'type':'String'},\n",
    "    {'field':'edition', 'type':'Price'}, # 'price' fields are how Dedupe models numerical data\n",
    "    {'field':'number_of_volumes', 'type':'Price'},\n",
    "    {'field':'author_name', 'type':'String'},\n",
    "    {'field':'date', 'type':'DateTime', 'yearfirst':True}, # 'yearfirst' indicates the date format\n",
    "    {'field':'full_book_title', 'type':'String'},\n",
    "    {'field':'darnton_record_id', 'type':'Price', 'has missing':True},\n",
    "    {'field':'client_code', 'type':'String'},\n",
    "    {'field':'total_number_of_volumes', 'type':'Price'}\n",
    "]\n",
    "\n",
    "deduper = dedupe_initialise(darnton_df, fields, settings_file, training_file, sample_size = 15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not using a pre-trained model, or if you have not provided a JSON file of labelled training examples, then you can use the cell below to label some record pairs in the console. The model with present you with two rows of the data frame, and ask you to type 'y' if they match, 'n' if they do not, or 'u' if you are unsure. Type 'f' when you have had enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.consoleLabel(deduper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.canopy_index:Removing stop word de\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing threshold based on a recall weighting of 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dedupe.backport:Dedupe does not currently support multiprocessing on Windows\n",
      "INFO:dedupe.api:Maximum expected recall and precision\n",
      "INFO:dedupe.api:recall: 0.788\n",
      "INFO:dedupe.api:precision: 0.692\n",
      "INFO:dedupe.api:With threshold: 0.369\n",
      "INFO:dedupe.canopy_index:Removing stop word de\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation complete. Threshold = 0.36868736147880554. It took 4.682 seconds.\n",
      "Clustering...\n",
      "Clustering complete. 1528 clusters found. It took 4.820 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Train the model, cluster the records and save\n",
    "deduper, matches = run_deduper(deduper, darnton_df, settings_file, training_file, recall_weight = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered = save_clusters(matches, darnton_df, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how well the model has done at linking the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stn_abbreviated_title</th>\n",
       "      <th>edition</th>\n",
       "      <th>number_of_volumes</th>\n",
       "      <th>author_name</th>\n",
       "      <th>copies_ordered</th>\n",
       "      <th>date</th>\n",
       "      <th>full_book_title</th>\n",
       "      <th>darnton_record_id</th>\n",
       "      <th>client_name</th>\n",
       "      <th>client_code</th>\n",
       "      <th>total_number_of_volumes</th>\n",
       "      <th>cluster</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>Journal de maupou</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Moufle d'Angerville, Berthélemy-François-Joseph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1775-04-17</td>\n",
       "      <td>Journal historique de la révolution opérée dan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cl1510</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>0.853935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>Journal de maupou</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Pidansat de Mairobert, Mathieu-François</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1775-04-17</td>\n",
       "      <td>Journal historique de la révolution opérée dan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cl1510</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>0.853935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     stn_abbreviated_title  edition  number_of_volumes  \\\n",
       "4788     Journal de maupou     12.0                7.0   \n",
       "4789     Journal de maupou     12.0                7.0   \n",
       "\n",
       "                                          author_name  copies_ordered  \\\n",
       "4788  Moufle d'Angerville, Berthélemy-François-Joseph             NaN   \n",
       "4789          Pidansat de Mairobert, Mathieu-François             NaN   \n",
       "\n",
       "            date                                    full_book_title  \\\n",
       "4788  1775-04-17  Journal historique de la révolution opérée dan...   \n",
       "4789  1775-04-17  Journal historique de la révolution opérée dan...   \n",
       "\n",
       "      darnton_record_id client_name client_code  total_number_of_volumes  \\\n",
       "4788                NaN         NaN      cl1510                     42.0   \n",
       "4789                NaN         NaN      cl1510                     42.0   \n",
       "\n",
       "      cluster  confidence  \n",
       "4788   1329.0    0.853935  \n",
       "4789   1329.0    0.853935  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered[clustered['cluster'] == random.randint(0, len(matches) + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of the Darnton orders has it linked to a sale in the FBTEE data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 3398 orders in Darnton's dataset, 1427 have been linked to a sale, or 42.0%.\n"
     ]
    }
   ],
   "source": [
    "darnton_orders = len(clustered[pd.notnull(clustered.darnton_record_id)])\n",
    "darnton_clustered = len(clustered[pd.notnull(clustered.darnton_record_id) & pd.notnull(clustered.cluster)])\n",
    "print(f'Of the {darnton_orders} orders in Darnton\\'s dataset, {darnton_clustered} have been linked to a sale, or {darnton_clustered / darnton_orders * 100:.1f}%.' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
