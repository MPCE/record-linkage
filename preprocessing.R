########################################################################################################
#
# MPCE Record Linkage Project
#
# Project: Mapping Print, Charting Enlightenment
#
# Script: Importing data from database, wrangling into a form appropriate for passing to dedupe library
#
# Authors: Michael Falk
#
# Date: 30/10/18
#
########################################################################################################

# Load necessary packages
library(tidyverse) # for data manipulation
library(magrittr) # for a more powerful piping operator
library(DBI) # to enable database connection
library(RMySQL) # a simple API for connecting to a MySQL database

# SECTION 1: ESTABLISH CONNECTION TO DATABASE

# This script supposes that you a running a local copy of the database accessible at 'localhost'.
manuscripts <- dbConnect(MySQL(), user="root", dbname="manuscripts", host="localhost")
info_schema <- dbConnect(MySQL(), user="root", dbname="information_schema", host="localhost")

# Import main datasets.
editions <- manuscripts %>%
  dbSendQuery(paste0("SELECT * FROM manuscript_books_authors ",
                     "LEFT JOIN manuscript_books_editions ",
                     "ON manuscript_books_authors.book_code = manuscript_books_editions.book_code ",
                     "LEFT JOIN manuscript_authors ",
                     "ON manuscript_books_authors.author_code = manuscript_authors.author_code")) %>%
  fetch(n = Inf) %>%
  .[,c(-5,-28)] %>% # delete duplicate columns generated by the queries.
  as_tibble() %>% # convert to tibble for easier manipulation
  select(super_book_code, full_book_title, short_book_titles, translated_title,
         stated_publication_places, stated_publication_years,
         author_name, author_code) # only keep necessary columns

illegal_titles <- manuscripts %>%
  dbSendQuery("SELECT * FROM manuscript_titles_illegal") %>%
  fetch(n = Inf) %>%
  as_tibble() %>%
  filter(record_status != "DELETED") %>% # filter out deleted records
  select(-record_status, -illegal_folio, -bastille_book_category, -bastille_total_volumes,
         -bastille_current_volumes, -bastille_copies_number) # Drop columns irrelevant to record linkage task

# Have a look at some random selections of the two tables:
sample_n(editions, 15)
sample_n(illegal_titles, 15)

# SECTION 2: COMBINE RECORDS INTO SINGLE TABLE

# The overall aim is to join both tables together. This basically means cleaning 'illegal_titles' so the fields
# have the same kind of data in them as in 'editions', and also changing the column names so that the computer
# has no trouble working out which columns encode the same information.

# First clean up the illegal_titles table.
# These first few lines strip away everything except for the place of publication from the imprint data.
# It was all hard-coded by MF using trial and error.
illegal_titles %<>%
  mutate(bastille_imprint_full = gsub("Published in", "", bastille_imprint_full), # remove phrase 'published in'
         bastille_imprint_full = gsub(", publisher not identified", "", bastille_imprint_full), # remove phrase 'publisher not identified'
         bastille_imprint_full = gsub("No .+[.]", "", bastille_imprint_full),  # remove any notes like 'No publisher identified.'
         bastille_imprint_full = gsub("[^[:alnum:]_].+", "", bastille_imprint_full), # remove everything after the first punctuation mark
         bastille_imprint_full = gsub("[0-9]", "", bastille_imprint_full), # remove numbers
         bastille_imprint_full = gsub("[[:punct:]]", "", bastille_imprint_full), # strip punctuation
         bastille_imprint_full = gsub("contains|source|this|place|various|dates|deux|publication|music|printed|trans", "", bastille_imprint_full, ignore.case = T), # strip out some particular words that are specific to this column
         bastille_imprint_full = str_squish(bastille_imprint_full), # remove leading and trailing whitespace
         bastille_imprint_full = gsub("^.{1,3}$", "", bastille_imprint_full) # remove any entries only 2-3 characters long
  )

# Have a look at results:
select(illegal_titles, bastille_imprint_full) %>%
  filter(nchar(bastille_imprint_full) > 0) %>%
  sample_n(15)

# Now try to extract place of publication from the illegal_notes field
illegal_titles %<>%
  mutate(illegal_notes = str_match(illegal_notes, "Published in (.+)")[,2], # grab everything after phrase 'published in'
         illegal_notes = word(illegal_notes, 1, sep = regex("[:, ]")), # just keep first word of new string, which is where the place name is
         illegal_notes = gsub("[0-9]", "", illegal_notes), # delete dates from field
         illegal_notes = gsub("^.{1,3}$", "", illegal_notes) # delete short rubbishy strings
  )

# Have a look at the results
select(illegal_titles, illegal_notes) %>%
  filter(nchar(illegal_notes) > 0) %>%
  sample_n(15)

# Now that those two columns have been fixed up, we can coalesce them.
illegal_titles %<>%
  mutate(stated_publication_places = coalesce(illegal_notes, bastille_imprint_full)) %>%
  select(-illegal_notes, -bastille_imprint_full)

# Have a look at the results
sample_n(illegal_titles, 15)

# The next step is to clean the date field for the illegal books. Luckily this is really easy.
illegal_titles %<>%
  mutate(stated_publication_years = gsub("No Date Available", "", illegal_date)) %>% # remove extraneous string and also change the column name
  select(-illegal_date) # drop old column.

# Have a look at the results
illegal_titles %>%
  filter(nchar(stated_publication_years) > 0) %>%
  sample_n(15)

# Finish renaming the columns
illegal_titles %<>%
  rename(super_book_code = illegal_super_book_code,
         full_book_title = illegal_full_book_title,
         author_code = illegal_author_code,
         author_name = illegal_author_name) %>%
  mutate( # we should also duplicate the title data in case it matches a different column in the editions table
    short_book_titles = full_book_title,
    translated_title = full_book_title
  )

# Now that the data has been cleaned, we just need to combine the tables.
# We can see which columns the tables have in common ...
intersect(colnames(illegal_titles), colnames(editions))
# ... and which they do not:
setdiff(colnames(illegal_titles), colnames(editions))

# Now we can simply perform a full join to concatenate the tables.
combined_data <- full_join(illegal_titles, editions)

# See the results
sample_n(combined_data, 15)

# Export so it can be passed to dedupe library in Python.
combined_data %>%
  write_csv("combined_editions_illegal_books.csv")
