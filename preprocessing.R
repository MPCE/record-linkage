########################################################################################################
#
# MPCE Record Linkage Project
#
# Project: Mapping Print, Charting Enlightenment
#
# Script: Importing data from database, wrangling into a form appropriate for passing to dedupe library
#
# Authors: Michael Falk, Simon Burrows
#
# Date: 30/10/18, 6/11/18
#
########################################################################################################

# HOW TO USE THIS SCRIPT

# This script is a record of MF's data wrangling. It is not designed to be executed from start to finish.
# It should work if you do that, but you might end up reading and writing more files that you would like.
# Instead, just execute the code blocks relevant to you at the time.

# Load necessary packages
library(tidyverse) # for data manipulation
library(magrittr) # for a more powerful piping operator
library(DBI) # to enable database connection
library(RMySQL) # a simple API for connecting to a MySQL database
library(readxl)
library(lubridate)
library(jsonlite)

# SECTION 1: ESTABLISH CONNECTION TO DATABASE

# This script supposes that you a running a local copy of the database accessible at 'localhost'.
manuscripts <- dbConnect(MySQL(), user="root", dbname="manuscripts", host="localhost")
info_schema <- dbConnect(MySQL(), user="root", dbname="information_schema", host="localhost")

# Import main datasets.

editions <- manuscripts %>%
  dbSendQuery(paste0("SELECT * FROM manuscript_books AS mb ",
                     "LEFT OUTER JOIN manuscript_books_editions AS mbe ",
                     "ON mb.super_book_code = mbe.super_book_code ",
                     "LEFT OUTER JOIN manuscript_books_authors AS mba ",
                     "ON mbe.book_code = mba.book_code ",
                     "LEFT OUTER JOIN manuscript_authors AS ma ",
                     "ON mba.author_code = ma.author_code;")) %>%
  fetch(n = Inf) %>%
  .[,c(-5,-28)] %>% # delete duplicate columns generated by the queries.
  as_tibble() %>% # convert to tibble for easier manipulation
  select(super_book_code, full_book_title, stated_publication_places, stated_publication_years,
         author_name, author_code) # only keep necessary columns

illegal_titles <- manuscripts %>%
  dbSendQuery("SELECT * FROM manuscript_titles_illegal") %>%
  fetch(n = Inf) %>%
  as_tibble() %>%
  filter(record_status != "DELETED") %>% # filter out deleted records
  select(-record_status, -illegal_folio, -bastille_book_category, -bastille_total_volumes,
         -bastille_current_volumes, -bastille_copies_number) # Drop columns irrelevant to record linkage task

# Have a look at some random selections of the two tables:
sample_n(editions, 15)
sample_n(illegal_titles, 15)

# SECTION 2: COMBINE RECORDS INTO SINGLE TABLE

# The overall aim is to join both tables together. This basically means cleaning 'illegal_titles' so the fields
# have the same kind of data in them as in 'editions', and also changing the column names so that the computer
# has no trouble working out which columns encode the same information.

# First clean up the illegal_titles table.
# These first few lines strip away everything except for the place of publication from the imprint data.
# It was all hard-coded by MF using trial and error.
illegal_titles %<>%
  mutate(bastille_imprint_full = gsub("Published in", "", bastille_imprint_full), # remove phrase 'published in'
         bastille_imprint_full = gsub(", publisher not identified", "", bastille_imprint_full), # remove phrase 'publisher not identified'
         bastille_imprint_full = gsub("No .+[.]", "", bastille_imprint_full),  # remove any notes like 'No publisher identified.'
         bastille_imprint_full = gsub("[^[:alnum:]_].+", "", bastille_imprint_full), # remove everything after the first punctuation mark
         bastille_imprint_full = gsub("[0-9]", "", bastille_imprint_full), # remove numbers
         bastille_imprint_full = gsub("[[:punct:]]", "", bastille_imprint_full), # strip punctuation
         bastille_imprint_full = gsub("contains|source|this|place|various|dates|deux|publication|music|printed|trans", "", bastille_imprint_full, ignore.case = T), # strip out some particular words that are specific to this column
         bastille_imprint_full = str_squish(bastille_imprint_full), # remove leading and trailing whitespace
         bastille_imprint_full = gsub("^.{1,3}$", "", bastille_imprint_full) # remove any entries only 2-3 characters long
  )

# Have a look at results:
select(illegal_titles, bastille_imprint_full) %>%
  filter(nchar(bastille_imprint_full) > 0) %>%
  sample_n(15)

# Now try to extract place of publication from the illegal_notes field
illegal_titles %<>%
  mutate(illegal_notes = str_match(illegal_notes, "Published in (.+)")[,2], # grab everything after phrase 'published in'
         illegal_notes = word(illegal_notes, 1, sep = regex("[:, ]")), # just keep first word of new string, which is where the place name is
         illegal_notes = gsub("[0-9]", "", illegal_notes), # delete dates from field
         illegal_notes = gsub("^.{1,3}$", "", illegal_notes) # delete short rubbishy strings
  )

# Have a look at the results
select(illegal_titles, illegal_notes) %>%
  filter(nchar(illegal_notes) > 0) %>%
  sample_n(15)

# Now that those two columns have been fixed up, we can coalesce them.
illegal_titles %<>%
  mutate(stated_publication_places = coalesce(illegal_notes, bastille_imprint_full)) %>%
  select(-illegal_notes, -bastille_imprint_full)

# Have a look at the results
sample_n(illegal_titles, 15)

# The next step is to clean the date field for the illegal books. Luckily this is really easy.
illegal_titles %<>%
  mutate(stated_publication_years = gsub("No Date Available", "", illegal_date)) %>% # remove extraneous string and also change the column name
  select(-illegal_date) # drop old column.

# Have a look at the results
illegal_titles %>%
  filter(nchar(stated_publication_years) > 0) %>%
  sample_n(15)

# Finish renaming the columns
illegal_titles %<>%
  rename(super_book_code = illegal_super_book_code,
         full_book_title = illegal_full_book_title,
         author_code = illegal_author_code,
         author_name = illegal_author_name)

# Now that the data has been cleaned, we just need to combine the tables.
# We can see which columns the tables have in common ...
intersect(colnames(illegal_titles), colnames(editions))
# ... and which they do not:
setdiff(colnames(illegal_titles), colnames(editions))

# Now we can simply perform a full join to concatenate the tables.
combined_data <- full_join(illegal_titles, editions)

# One final thing: remove 'n. pl.' from stated_publication_places:
combined_data %<>%
  mutate(stated_publication_places = gsub("n[.]pl[.]", "", stated_publication_places))

# See the results
sample_n(combined_data, 15)

# Export so it can be passed to dedupe library in Python.
combined_data %>%
  write_csv("combined_editions_illegal_books.csv")

# SECTION 3: COMBINE EDITIONS DATA WITH DARNTON'S DATA

# Simon has provided client codes for Darnton's booksellers.
codes = c("Charmet" = "cl0274", "Lepagnez" = "cl0288", "Rigaud" = "cl1266", "Fontanel" = "cl1224",
          "Letourmy" = "cl1514", "Sens" = "cl2067", "Caldesaigues" = "cl1203", "Gaude" = "cl1472",
          "Buchet" = "cl1468", "Mossy" = "cl1210", "Robert&Gauthier" = "cl0353", "Bergeret" = "cl0335",
          "Lair" = "cl0328", "Couret de Villeneuve" = "cl1510", "Pavie" = "cl1834", "Chevrier" = "cl1763")

# Import Darnton's data, then wrangle to put in the same format as the FBTEE data
darnton <- read_xlsx("darnton_files/darnton_data.xlsx") %>%
  rename(darnton_record_id = X__1,
         stn_abbreviated_title = `Titre de l'ouvrage`,
         edition = format,
         number_of_volumes = volumes,
         copies_ordered = `Nbre d'ouvrages commandés`,
         date = `Dates des commandes`,
         full_book_title = `Editions et Commentaires`,
         client_name = Libraire,
         author_name = Auteur) %>%
  mutate(client_code = map_chr(client_name, function(x) codes[x])) %>% # add client codes
  mutate(number_of_volumes = str_match(number_of_volumes, "(\\d+) vol")[,2], # quantify volume information
         number_of_volumes = as.numeric(number_of_volumes),
         copies_ordered = as.numeric(copies_ordered)) %>% # convert copies ordered to numeric data
  mutate(total_number_of_volumes = copies_ordered * number_of_volumes) %>% # infer number of volumes ordered
  mutate(edition = str_replace(edition, "folio", "2"), # pull out number of leaves
         edition = str_match(edition, "\\d+"),
         edition = as.numeric(edition)) %>%
  mutate(date = dmy(date)) %>% # convert date to common format
  select(-`Remarques générales`, -villes) # drop extraneous columns

# Since Darnton's data is about orders for books, it might be good to compare it to our transactions data too.
orders <- manuscripts %>%
  dbSendQuery("SELECT * FROM orders") %>%
  fetch(n = Inf) %>%
  as_tibble()

editions <- manuscripts %>%
  dbSendQuery(paste0("SELECT * FROM manuscript_books_authors ",
                     "LEFT JOIN manuscript_books_editions ",
                     "ON manuscript_books_authors.book_code = manuscript_books_editions.book_code ",
                     "LEFT JOIN manuscript_authors ",
                     "ON manuscript_books_authors.author_code = manuscript_authors.author_code")) %>%
  fetch(n = Inf) %>%
  .[,c(-5,-28)] %>% # delete duplicate columns generated by the queries.
  as_tibble()

transactions <- manuscripts %>%
  dbSendQuery("SELECT * FROM transactions") %>%
  fetch(n = Inf) %>%
  as_tibble() %>%
  select(-super_book_code) %>%
  left_join(orders, by = "order_code") %>%
  left_join(editions, by = "book_code") %>%
  filter(client_code %in% codes, # Only want the clients from Darnton's sample
         str_detect(direction_of_transaction, "Out")) %>% # only want sales
  mutate(date = ymd(date)) %>% # convert date to common format
  mutate(total_number_of_volumes = abs(total_number_of_volumes)) %>% # don't want negative numbers
  mutate(edition = str_replace(edition, "Folio|folio", "2"), # convert edition data to common format
         edition = str_extract(edition, "\\d+"),
         edition = as.numeric(edition))

rm(orders, editions)

# Now join the tables together for deduplication.
darnton_combined_data <- bind_rows(darnton, transactions) %>%
  select(colnames(darnton)) %T>%
  write_csv("darnton_files/darnton_combined.csv")
